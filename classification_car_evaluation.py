# ============================================================================
# მანქანის შეფასების კლასიფიკაცია
# ============================================================================
# ეს სკრიპტი აჩვენებს სამ კლასიფიკაციის ალგორითმს:
# 1. გადაწყვეტილების ხის კლასიფიკატორი კონფუზიის მატრიცით
# 2. ვექტორული მხარდაჭერის მანქანა (SVM) კონფუზიის მატრიცით
# 3. ლოგისტიკური რეგრესია ROC მრუდით
# მონაცემთა ნაკრები: car_evaluation.csv
# ============================================================================

# საჭირო ბიბლიოთეკების შემოტანა
import pandas as pd  # მონაცემთა მანიპულაციისა და ანალიზისთვის
from sklearn.preprocessing import LabelEncoder  # კატეგორიული ტექსტური მონაცემების რიცხვებად გადაქცევისთვის
from sklearn.tree import DecisionTreeClassifier  # კლასიფიკაციისთვის გადაწყვეტილების ხის ალგორითმი
from sklearn.svm import SVC  # ვექტორული მხარდაჭერის კლასიფიკატორის ალგორითმი
from sklearn.linear_model import LogisticRegression  # ლოგისტიკური რეგრესიის ალგორითმი
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score  # შეფასების მეტრიკები
import matplotlib.pyplot as plt  # ვიზუალიზაციების შესაქმნელად
from sklearn.model_selection import train_test_split  # მონაცემების სწავლებისა და ტესტირების სეტებად დაყოფისთვის

# ============================================================================
# მონაცემების ჩატვირთვა და წინასწარი დამუშავება
# ============================================================================

# მანქანის შეფასების CSV ფაილის წაკითხვა (ორიგინალურ ფაილში სათაურები არ არის)
car = pd.read_csv("car_evaluation.csv", header=None)

# მონაცემთა ნაკრებს მნიშვნელოვანი სვეტების სახელების მინიჭება
car.columns = ["Buying_Price", "Maintance_cost", "N_of_doors", "N_person", "lug_boot",
               "safety", "Class"]

# სამიზნე ცვლადის (Class) ბინარულ მნიშვნელობებად გადაქცევა:
# 'vgood' (ძალიან კარგი) = 1, ყველა სხვა ('unacc', 'acc', 'good') = 0
car['Class'] = car['Class'].map({'unacc': 0, 'acc': 0, 'good': 0, 'vgood': 1})

# ყველა კატეგორიული (object ტიპის) სვეტის რიცხვებად გადაქცევა LabelEncoder-ის გამოყენებით
for col in car.columns:
    if car[col].dtype == 'object':  # შემოწმება, შეიცავს თუ არა სვეტი ტექსტურ მონაცემებს
        car[col] = LabelEncoder().fit_transform(car[col])  # ტექსტის რიცხვებად გადაქცევა

# პირველი 5 მწკრივის ჩვენება წინასწარი დამუშავების შესამოწმებლად
print("წინასწარ დამუშავებული მონაცემები:")
print(car.head())
print("\n")

# ფუნქციების (X) და სამიზნე ცვლადის (y) გამოყოფა
y = car['Class']  # სამიზნე ცვლადი (რისი პროგნოზირებაც გვინდა)
X = car.drop('Class', axis=1)  # ფუნქციები (ყველა სვეტი Class-ის გარდა)

# მონაცემების სწავლების (80%) და ტესტირების (20%) სეტებად დაყოფა
# random_state=1 უზრუნველყოფს განმეორებადობას (იგივე დაყოფა ყოველ ჯერზე)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

# ============================================================================
# მოდელი 1: გადაწყვეტილების ხის კლასიფიკატორი
# ============================================================================

print("=" * 70)
print("გადაწყვეტილების ხის კლასიფიკატორი")
print("=" * 70)

# გადაწყვეტილების ხის მოდელის შექმნა ნაგულისხმევი პარამეტრებით
model_dt = DecisionTreeClassifier()

# მოდელის სწავლება სწავლების მონაცემებით
model_dt.fit(X_train, y_train)

# ტესტის მონაცემებზე სიზუსტის გამოთვლა და ჩვენება
accuracy_dt = model_dt.score(X_test, y_test)
print(f"გადაწყვეტილების ხის სიზუსტე: {accuracy_dt:.4f}")

# ტესტის მონაცემებზე პროგნოზების გაკეთება
y_prediction_dt = model_dt.predict(X_test)

# კონფუზიის მატრიცის შექმნა პროგნოზის შესრულების სანახავად
conf_matrix_dt = confusion_matrix(y_test, y_prediction_dt)

# კონფუზიის მატრიცის ვიზუალური ჩვენების შექმნა
result_dt = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_dt, display_labels=model_dt.classes_)
result_dt.plot()  # კონფუზიის მატრიცის გამოსახვა
plt.title("გადაწყვეტილების ხე - კონფუზიის მატრიცა")  # სათაურის დამატება
plt.show()  # გრაფიკის ჩვენება

print("\n")

# ============================================================================
# მოდელი 2: ვექტორული მხარდაჭერის მანქანა (SVM)
# ============================================================================

print("=" * 70)
print("ვექტორული მხარდაჭერის მანქანა (SVM)")
print("=" * 70)

# SVM მოდელის შექმნა ალბათობის შეფასებით
# probability=True საშუალებას გვაძლევს მივიღოთ ალბათობის ქულები პროგნოზებისთვის
model_svm = SVC(probability=True)

# SVM მოდელის სწავლება
model_svm.fit(X_train, y_train)

# სიზუსტის გამოთვლა და ჩვენება
accuracy_svm = model_svm.score(X_test, y_test)
print(f"SVM სიზუსტე: {accuracy_svm:.4f}")

# ტესტის მონაცემებზე პროგნოზების გაკეთება
y_prediction_svm = model_svm.predict(X_test)

# კონფუზიის მატრიცის შექმნა
conf_matrix_svm = confusion_matrix(y_test, y_prediction_svm)

# კონფუზიის მატრიცის ვიზუალური ჩვენება
result_svm = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_svm, display_labels=model_svm.classes_)
result_svm.plot()
plt.title("SVM - კონფუზიის მატრიცა")
plt.show()

print("\n")

# ============================================================================
# მოდელი 3: ლოგისტიკური რეგრესია ROC მრუდით
# ============================================================================

print("=" * 70)
print("ლოგისტიკური რეგრესია ROC მრუდით")
print("=" * 70)

# ლოგისტიკური რეგრესიის მოდელის შექმნა
model_lr = LogisticRegression()

# მოდელის სწავლება
model_lr.fit(X_train, y_train)

# დადებითი კლასის (კლასი 1) ალბათობის პროგნოზების მიღება
# [:,1] ირჩევს მხოლოდ კლასი 1-ის ალბათობებს
positive_probabilities = model_lr.predict_proba(X_test)[:, 1]

# ROC მრუდის მნიშვნელობების გამოთვლა
# fpr = ცრუ დადებითი მაჩვენებელი, tpr = ნამდვილი დადებითი მაჩვენებელი, threshold = გადაწყვეტილების ბარიერები
fpr, tpr, threshold = roc_curve(y_test, positive_probabilities)

# ROC მრუდის ქვეშ არსებული ფართობის (AUC ქულა) გამოთვლა
# AUC მერყეობს 0-დან 1-მდე, სადაც 1 არის სრულყოფილი კლასიფიკაცია
area = roc_auc_score(y_test, positive_probabilities)

# ROC მრუდის გამოსახვა
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC მრუდი (AUC = {area:.4f})')  # AUC-სთან ერთად გამოსახვა
plt.plot([0, 1], [0, 1], 'r--', label='შემთხვევითი კლასიფიკატორი')  # დიაგონალური ხაზი მითითებისთვის
plt.xlabel('ცრუ დადებითი მაჩვენებელი')  # X-ღერძის ხელმოწერა
plt.ylabel('ნამდვილი დადებითი მაჩვენებელი')  # Y-ღერძის ხელმოწერა
plt.title('ლოგისტიკური რეგრესია - ROC მრუდი')  # სათაური
plt.legend()  # ლეგენდის ჩვენება
plt.grid(True)  # ბადის დამატება უკეთესი წაკითხვისთვის
plt.show()  # გრაფიკის ჩვენება

print(f"ლოგისტიკური რეგრესიის AUC ქულა: {area:.4f}")
print("\n")

# ============================================================================
# შეჯამება
# ============================================================================

print("=" * 70)
print("შედეგების შეჯამება")
print("=" * 70)
print(f"გადაწყვეტილების ხის სიზუსტე: {accuracy_dt:.4f}")
print(f"SVM სიზუსტე: {accuracy_svm:.4f}")
print(f"ლოგისტიკური რეგრესიის AUC: {area:.4f}")
print("=" * 70)
