# ============================================================================
# გულის დაავადების პროგნოზირების კლასიფიკაცია
# ============================================================================
# ეს სკრიპტი აჩვენებს მოწინავე კლასიფიკაციას:
# 1. ვექტორული მხარდაჭერის მანქანა (SVM) Pipeline-ით
# 2. MinMaxScaler ფუნქციების ნორმალიზაციისთვის
# 3. GridSearchCV ჰიპერპარამეტრების ოპტიმიზაციისთვის
# მონაცემთა ნაკრები: heart.csv (Heart Disease UCI dataset)
# ============================================================================

# საჭირო ბიბლიოთეკების შემოტანა
import pandas as pd  # მონაცემთა მანიპულაციისთვის
from sklearn.svm import SVC  # ვექტორული მხარდაჭერის კლასიფიკატორი
from sklearn.pipeline import Pipeline  # წინასწარი დამუშავებისა და მოდელის ერთად დაკავშირებისთვის
from sklearn.preprocessing import MinMaxScaler  # ფუნქციების [0,1] დიაპაზონში ნორმალიზაციისთვის
from sklearn.model_selection import train_test_split, GridSearchCV  # მონაცემების დაყოფისა და ოპტიმიზაციისთვის

# ============================================================================
# მონაცემების ჩატვირთვა და გამოკვლევა
# ============================================================================

# გულის დაავადების მონაცემთა ნაკრების ჩატვირთვა
heart = pd.read_csv("heart.csv")

print("=" * 70)
print("გულის დაავადების მონაცემთა ნაკრები")
print("=" * 70)
print("მონაცემთა ნაკრების პირველი 5 მწკრივი:")
print(heart.head())
print(f"\nმონაცემთა ნაკრების ფორმა: {heart.shape}")
print(f"ფუნქციების რაოდენობა: {heart.shape[1] - 1}")  # მინუს 1 სამიზნე სვეტისთვის
print(f"ნიმუშების რაოდენობა: {heart.shape[0]}")
print(f"\nსვეტების სახელები: {list(heart.columns)}")
print(f"\nსამიზნე ცვლადის (target) მნიშვნელობები: {heart['target'].unique()}")
print("  0 = გულის დაავადება არ არის, 1 = გულის დაავადება არსებობს")
print("\n")

# გამოტოვებული მნიშვნელობების შემოწმება
print("გამოტოვებული მნიშვნელობები:")
print(heart.isnull().sum())
print("\n")

# ძირითადი სტატისტიკის ჩვენება
print("მონაცემთა ნაკრების სტატისტიკა:")
print(heart.describe())
print("\n")

# ============================================================================
# მონაცემების მომზადება
# ============================================================================

print("=" * 70)
print("მონაცემების მომზადება")
print("=" * 70)

# ფუნქციების (X) და სამიზნე ცვლადის (Y) გამოყოფა
X = heart.drop("target", axis=1)  # ყველა სვეტი 'target'-ის გარდა
Y = heart["target"]               # მხოლოდ 'target' სვეტი

print(f"ფუნქციები (X) ფორმა: {X.shape}")
print(f"სამიზნე (Y) ფორმა: {Y.shape}")
print(f"\nსამიზნის განაწილება:")
print(Y.value_counts())
print(f"  კლასი 0 (დაავადება არ არის): {Y.value_counts()[0]} ნიმუში")
print(f"  კლასი 1 (დაავადება არსებობს): {Y.value_counts()[1]} ნიმუში")
print("\n")

# მონაცემების სწავლების (80%) და ტესტირების (20%) სეტებად დაყოფა
# შენიშვნა: random_state არ არის მითითებული, ამიტომ დაყოფა ყოველ გაშვებაზე განსხვავებული იქნება
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)

print(f"სწავლების სეტის ზომა: {X_train.shape[0]} ნიმუში")
print(f"ტესტირების სეტის ზომა: {X_test.shape[0]} ნიმუში")
print("\n")

# ============================================================================
# მოდელი 1: SVM PIPELINE-ით (ბაზისური ხაზი)
# ============================================================================

print("=" * 70)
print("ვექტორული მხარდაჭერის მანქანა (SVM) PIPELINE-ით - ბაზისური ხაზი")
print("=" * 70)

# Pipeline-ის შექმნა, რომელიც აერთიანებს წინასწარ დამუშავებასა და კლასიფიკაციას
# რატომ Pipeline?
# - MinMaxScaler ნორმალიზებს ფუნქციებს [0,1] დიაპაზონში
# - SVM უკეთ მუშაობს ნორმალიზებულ ფუნქციებთან
# - Pipeline ხელს უშლის მონაცემების გაჟონვას scaler-ის მხოლოდ სწავლების მონაცემებზე მორგებით
hybrid_baseline = Pipeline(steps=[
    ("scaler", MinMaxScaler()),  # ნაბიჯი 1: ფუნქციების [0, 1] დიაპაზონში მასშტაბირება
    ("algorithm", SVC())         # ნაბიჯი 2: SVM კლასიფიკატორის გამოყენება
])

print("Pipeline-ის ნაბიჯები:")
print("  1. MinMaxScaler: ნორმალიზებს ყველა ფუნქციას [0, 1] დიაპაზონში")
print("  2. SVC: ვექტორული მხარდაჭერის კლასიფიკატორი ნაგულისხმევი პარამეტრებით")
print("\nმოდელის სწავლება...")

# მთელი Pipeline-ის მორგება სწავლების მონაცემებზე
hybrid_baseline.fit(X_train, y_train)

# ტესტის მონაცემებზე სიზუსტის გამოთვლა
accuracy_baseline = hybrid_baseline.score(X_test, y_test)

print(f"\nSVM (ბაზისური ხაზი) სიზუსტე: {accuracy_baseline:.4f}")
print(f"SVM (ბაზისური ხაზი) სიზუსტე: {accuracy_baseline*100:.2f}%")
print("\n")

# ============================================================================
# მოდელი 2: SVM GRID SEARCH ოპტიმიზაციით
# ============================================================================

print("=" * 70)
print("SVM GRID SEARCH ჰიპერპარამეტრების ოპტიმიზაციით")
print("=" * 70)

# საბაზისო SVM მოდელის შექმნა (პარამეტრები ოპტიმიზირდება)
model_svm = SVC()

# ჰიპერპარამეტრების დარეგულირებისთვის პარამეტრების ბადის განსაზღვრა
# C არის რეგულარიზაციის პარამეტრი:
# - მცირე C: მეტი რეგულარიზაცია (უფრო მარტივი მოდელი, შეიძლება ნაკლებად მოერგოს)
# - დიდი C: ნაკლები რეგულარიზაცია (რთული მოდელი, შეიძლება გადაჭარბებით მოერგოს)
parameters = {
    "C": [0.01, 0.5, 0.7, 0.08, 0.12, 0.8]  # შესამოწმებელი სხვადასხვა რეგულარიზაციის სიძლიერე
}

print("ჰიპერპარამეტრების ბადე:")
print(f"  C (რეგულარიზაციის პარამეტრი): {parameters['C']}")
print(f"  შესამოწმებელი პარამეტრის კომბინაციების საერთო რაოდენობა: {len(parameters['C'])}")
print("\nრა არის C პარამეტრი?")
print("  - აკონტროლებს გლუვ გადაწყვეტილების საზღვარსა და")
print("    სწავლების წერტილების სწორ კლასიფიკაციას შორის ბალანსს")
print("  - მცირე C: უფრო ფართო ზღვარი, მეტი სწავლების შეცდომა დაშვებულია")
print("  - დიდი C: უფრო ვიწრო ზღვარი, ნაკლები სწავლების შეცდომა დაშვებულია")
print("\n5-ჯერადი ჯვარედინი ვალიდაციით Grid Search-ის დაწყება...")

# GridSearchCV ობიექტის შექმნა
# estimator: ოპტიმიზაციისთვის მოდელი (SVM)
# param_grid: შესამოწმებელი პარამეტრის მნიშვნელობები
# scoring: ოპტიმიზაციის მეტრიკა (სიზუსტე)
# cv=5: მტკიცე შეფასებისთვის 5-ჯერადი ჯვარედინი ვალიდაციის გამოყენება
hybrid_optimized = GridSearchCV(
    estimator=model_svm,
    param_grid=parameters,
    scoring="accuracy",
    cv=5,  # 5-ჯერადი ჯვარედინი ვალიდაცია
    verbose=1  # პროგრესის ჩვენება
)

# GridSearchCV-ის მორგება სწავლების მონაცემებზე
# ეს:
# 1. შეამოწმებს თითოეულ C მნიშვნელობას
# 2. თითოეული C-ისთვის შეასრულებს 5-ჯერად ჯვარედინ ვალიდაციას
# 3. აირჩევს საუკეთესო საშუალო სიზუსტის მქონე C-ს
hybrid_optimized.fit(X_train, y_train)

# საუკეთესო პარამეტრებით სიზუსტის მიღება
accuracy_optimized = hybrid_optimized.score(X_test, y_test)

# ნაპოვნი საუკეთესო პარამეტრების მიღება
best_params = hybrid_optimized.best_params_

print("\nბადის ძიება დასრულებულია!")
print(f"\nSVM (ოპტიმიზებული) სიზუსტე: {accuracy_optimized:.4f}")
print(f"SVM (ოპტიმიზებული) სიზუსტე: {accuracy_optimized*100:.2f}%")
print(f"\nნაპოვნი საუკეთესო პარამეტრი:")
print(f"  C = {best_params['C']}")
print("\n")

# ============================================================================
# დეტალური GRID SEARCH შედეგები
# ============================================================================

print("=" * 70)
print("დეტალური GRID SEARCH შედეგები")
print("=" * 70)

# შედეგების DataFrame-ად გადაქცევა
results_df = pd.DataFrame(hybrid_optimized.cv_results_)

# ყველა შემოწმებული პარამეტრის ჩვენება მათი ქულებით
print("\nყველა შემოწმებული C მნიშვნელობა და მათი შესრულება:")
print("-" * 70)
for i, c_value in enumerate(parameters['C']):
    mean_score = results_df.loc[i, 'mean_test_score']
    std_score = results_df.loc[i, 'std_test_score']
    print(f"C = {c_value:5.2f}  |  საშუალო CV სიზუსტე: {mean_score:.4f} (+/- {std_score:.4f})")
print("-" * 70)
print(f"საუკეთესო: C = {best_params['C']:5.2f}  |  ტესტის სიზუსტე: {accuracy_optimized:.4f}")
print("\n")

# ============================================================================
# მოდელების შედარება და გაუმჯობესების ანალიზი
# ============================================================================

print("=" * 70)
print("მოდელების შედარება")
print("=" * 70)
print(f"SVM (ბაზისური ხაზი) სიზუსტე:   {accuracy_baseline:.4f} ({accuracy_baseline*100:.2f}%)")
print(f"SVM (ოპტიმიზებული) სიზუსტე:  {accuracy_optimized:.4f} ({accuracy_optimized*100:.2f}%)")

# გაუმჯობესების გამოთვლა
improvement = (accuracy_optimized - accuracy_baseline) * 100
if improvement > 0:
    print(f"\nგაუმჯობესება: +{improvement:.2f}% (უკეთესი)")
elif improvement < 0:
    print(f"\nცვლილება: {improvement:.2f}% (ოდნავ უარესი)")
else:
    print(f"\nშესრულებაში ცვლილება არ არის")

print("\n")

# ============================================================================
# ჯვარედინი ვალიდაციის შეხედულებები
# ============================================================================

print("=" * 70)
print("ჯვარედინი ვალიდაციის შეხედულებები")
print("=" * 70)
print(f"საუკეთესო ჯვარედინი ვალიდაციის ქულა: {hybrid_optimized.best_score_:.4f}")
print(f"ტესტის სეტის ქულა: {accuracy_optimized:.4f}")

# გადაჭარბებული მორგების შემოწმება
cv_test_diff = hybrid_optimized.best_score_ - accuracy_optimized
if abs(cv_test_diff) < 0.05:
    print("\nმოდელის განზოგადება: კარგი")
    print("  CV და ტესტის ქულები მსგავსია (განსხვავება < 5%)")
elif cv_test_diff > 0.05:
    print("\nმოდელის განზოგადება: შესაძლო გადაჭარბებული მორგება")
    print(f"  CV ქულა {cv_test_diff*100:.2f}%-ით მაღალია ტესტის ქულაზე")
else:
    print("\nმოდელის განზოგადება: შესანიშნავი")
    print(f"  ტესტის ქულა რეალურად {abs(cv_test_diff)*100:.2f}%-ით მაღალია CV ქულაზე")

print("\n")

# ============================================================================
# ძირითადი შეხედულებები და რეკომენდაციები
# ============================================================================

print("=" * 70)
print("ძირითადი შეხედულებები და რეკომენდაციები")
print("=" * 70)
print("\n1. რატომ გამოვიყენოთ Pipeline?")
print("   ✓ ხელს უშლის მონაცემების გაჟონვას (scaler მხოლოდ სწავლების მონაცემებზე მორგებულია)")
print("   ✓ ამარტივებს კოდს (წინასწარი დამუშავება + მოდელი ერთ ობიექტში)")
print("   ✓ ამარტივებს განლაგებას (ერთი ობიექტი შესანახად/ჩასატვირთად)")
print("   ✓ უზრუნველყოფს იგივე წინასწარ დამუშავებას სწავლებისა და ტესტირებისთვის")

print("\n2. რატომ გამოვიყენოთ MinMaxScaler SVM-თან?")
print("   ✓ SVM მგრძნობიარეა ფუნქციების მასშტაბების მიმართ")
print("   ✓ დიდი დიაპაზონის ფუნქციები შეიძლება დომინირებდნენ მოდელში")
print("   ✓ მასშტაბირება აუმჯობესებს მოდელის კონვერგენციასა და შესრულებას")

print("\n3. რატომ გამოვიყენოთ GridSearchCV?")
print("   ✓ ავტომატურად პოულობს საუკეთესო ჰიპერპარამეტრებს")
print("   ✓ იყენებს ჯვარედინ ვალიდაციას მტკიცე შეფასებისთვის")
print("   ✓ ხელს უშლის ერთი სწავლების/ტესტის დაყოფაზე გადაჭარბებულ მორგებას")
print("   ✓ დაზოგავს დროს ხელით დარეგულირებასთან შედარებით")

print("\n4. C პარამეტრის ინტერპრეტაცია:")
print(f"   ოპტიმალური C = {best_params['C']}")
if best_params['C'] < 0.1:
    print("   → მცირე C: მოდელი უპირატესობას ანიჭებს უფრო მარტივ გადაწყვეტილების საზღვარს")
    print("   → მეტი რეგულარიზაცია, შეიძლება ნაკლებად მოერგოს რთულ ნიმუშებს")
elif best_params['C'] > 0.5:
    print("   → დიდი C: მოდელი უპირატესობას ანიჭებს სწავლების მონაცემებთან მჭიდრო მორგებას")
    print("   → ნაკლები რეგულარიზაცია, შეიძლება გადაჭარბებით მოერგოს სწავლების მონაცემებს")
else:
    print("   → საშუალო C: დაბალანსებული რეგულარიზაცია")
    print("   → კარგი ბალანსი მორგებასა და განზოგადებას შორის")

print("\n5. საბოლოო მოდელის შესრულება:")
print(f"   სიზუსტე: {accuracy_optimized*100:.2f}%")
if accuracy_optimized >= 0.85:
    print("   → შესანიშნავი შესრულება გულის დაავადების პროგნოზირებისთვის")
elif accuracy_optimized >= 0.75:
    print("   → კარგი შესრულება, შესაფერისია წინასწარი გამოკვლევისთვის")
elif accuracy_optimized >= 0.65:
    print("   → საშუალო შესრულება, შეიძლება დასჭირდეს ფუნქციების ინჟინერია")
else:
    print("   → საჭიროებს გაუმჯობესებას, განიხილეთ სხვა მიდგომა")

print("\n" + "=" * 70)
print("ანალიზი დასრულებულია")
print("=" * 70)
